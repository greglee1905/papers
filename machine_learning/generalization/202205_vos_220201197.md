# VOS: Learning What You Don't Know by Virtual Outlier Synthesis
Paper: [arxiv](https://arxiv.org/pdf/2202.01197.pdf)

TLDR: on data samples which are out-of-distribution (OOD), models can exercise high confidence. Virtual Outlier Synthesis provides a method for synthesizing representations of outliers to make an object detector more robust to unusual examples. Essentially this provides another method for adding a model's degree of certainty that an image is OOD (similiar to bayesian DL models). 

How? VOS looks at representations at the network's penultimate layer, then fits a gaussian distribution to the representations of each class and sampled a representation with low probability. (representation synthesization are easier to learn and are applicable to other applications). Outlier detection is performed by a regression layer which learns to compute its likelihood of an outlier where the loss function consisted of a bounding box regression loss that taught the model to locate objects in an image, a bounding box classification loss and an uncertainty loss that taught it to recognize certain objects (representations) as outliers

This helps to address the question of known unknowns but not unknown unknowns --> those things we can not synthesize (maybe lean this camp more towards bayesian models)